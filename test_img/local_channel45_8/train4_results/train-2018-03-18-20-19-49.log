I0318 20:19:50.048099  5933 caffe.cpp:204] Using GPUs 0, 1, 2, 3
I0318 20:19:50.049257  5933 caffe.cpp:209] GPU 0: GeForce GTX 1080 Ti
I0318 20:19:50.050077  5933 caffe.cpp:209] GPU 1: GeForce GTX 1080 Ti
I0318 20:19:50.050861  5933 caffe.cpp:209] GPU 2: GeForce GTX 1080 Ti
I0318 20:19:50.052673  5933 caffe.cpp:209] GPU 3: GeForce GTX 1080 Ti
I0318 20:19:50.747001  5933 solver.cpp:45] Initializing solver from parameters: 
test_iter: 5000
test_interval: 5000
base_lr: 0.01
display: 40
max_iter: 1000000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200000
snapshot: 50000
snapshot_prefix: "models/local_channel_vgg16/caffe_vgg16_train"
solver_mode: GPU
device_id: 0
net: "models/local_channel_vgg16/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "models/local_channel_vgg16/VGG16.v2.caffemodel"
I0318 20:19:50.747174  5933 solver.cpp:102] Creating training net from net file: models/local_channel_vgg16/train_val.prototxt
I0318 20:19:50.747655  5933 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0318 20:19:50.747689  5933 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0318 20:19:50.747692  5933 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0318 20:19:50.747906  5933 net.cpp:51] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/data/ImageNet/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 25
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_local_channel"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 8
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2_local_channel"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3_pointwise"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1_local_channel"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2_local_channel"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3_pointwise"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss/loss"
}
I0318 20:19:50.748078  5933 layer_factory.hpp:77] Creating layer data
I0318 20:19:50.748208  5933 db_lmdb.cpp:35] Opened lmdb examples/imagenet/ilsvrc12_train_lmdb
I0318 20:19:50.748248  5933 net.cpp:84] Creating Layer data
I0318 20:19:50.748256  5933 net.cpp:380] data -> data
I0318 20:19:50.748281  5933 net.cpp:380] data -> label
I0318 20:19:50.748292  5933 data_transformer.cpp:25] Loading mean file from: /home/data/ImageNet/data/ilsvrc12/imagenet_mean.binaryproto
I0318 20:19:50.752905  5933 data_layer.cpp:45] output data size: 25,3,224,224
I0318 20:19:50.802690  5933 net.cpp:122] Setting up data
I0318 20:19:50.802739  5933 net.cpp:129] Top shape: 25 3 224 224 (3763200)
I0318 20:19:50.802748  5933 net.cpp:129] Top shape: 25 (25)
I0318 20:19:50.802755  5933 net.cpp:137] Memory required for data: 15052900
I0318 20:19:50.802769  5933 layer_factory.hpp:77] Creating layer conv1_1
I0318 20:19:50.802800  5933 net.cpp:84] Creating Layer conv1_1
I0318 20:19:50.802814  5933 net.cpp:406] conv1_1 <- data
I0318 20:19:50.802841  5933 net.cpp:380] conv1_1 -> conv1_1
I0318 20:19:51.173657  5933 net.cpp:122] Setting up conv1_1
I0318 20:19:51.173698  5933 net.cpp:129] Top shape: 25 64 224 224 (80281600)
I0318 20:19:51.173703  5933 net.cpp:137] Memory required for data: 336179300
I0318 20:19:51.173730  5933 layer_factory.hpp:77] Creating layer relu1_1
I0318 20:19:51.173748  5933 net.cpp:84] Creating Layer relu1_1
I0318 20:19:51.173754  5933 net.cpp:406] relu1_1 <- conv1_1
I0318 20:19:51.173764  5933 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0318 20:19:51.173981  5933 net.cpp:122] Setting up relu1_1
I0318 20:19:51.173995  5933 net.cpp:129] Top shape: 25 64 224 224 (80281600)
I0318 20:19:51.173998  5933 net.cpp:137] Memory required for data: 657305700
I0318 20:19:51.174002  5933 layer_factory.hpp:77] Creating layer conv1_2
I0318 20:19:51.174019  5933 net.cpp:84] Creating Layer conv1_2
I0318 20:19:51.174026  5933 net.cpp:406] conv1_2 <- conv1_1
I0318 20:19:51.174032  5933 net.cpp:380] conv1_2 -> conv1_2
I0318 20:19:51.175150  5933 net.cpp:122] Setting up conv1_2
I0318 20:19:51.175168  5933 net.cpp:129] Top shape: 25 64 224 224 (80281600)
I0318 20:19:51.175173  5933 net.cpp:137] Memory required for data: 978432100
I0318 20:19:51.175182  5933 layer_factory.hpp:77] Creating layer relu1_2
I0318 20:19:51.175189  5933 net.cpp:84] Creating Layer relu1_2
I0318 20:19:51.175194  5933 net.cpp:406] relu1_2 <- conv1_2
I0318 20:19:51.175199  5933 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0318 20:19:51.175391  5933 net.cpp:122] Setting up relu1_2
I0318 20:19:51.175405  5933 net.cpp:129] Top shape: 25 64 224 224 (80281600)
I0318 20:19:51.175408  5933 net.cpp:137] Memory required for data: 1299558500
I0318 20:19:51.175415  5933 layer_factory.hpp:77] Creating layer pool1
I0318 20:19:51.175426  5933 net.cpp:84] Creating Layer pool1
I0318 20:19:51.175431  5933 net.cpp:406] pool1 <- conv1_2
I0318 20:19:51.175437  5933 net.cpp:380] pool1 -> pool1
I0318 20:19:51.175508  5933 net.cpp:122] Setting up pool1
I0318 20:19:51.175518  5933 net.cpp:129] Top shape: 25 64 112 112 (20070400)
I0318 20:19:51.175520  5933 net.cpp:137] Memory required for data: 1379840100
I0318 20:19:51.175524  5933 layer_factory.hpp:77] Creating layer conv2_1
I0318 20:19:51.175534  5933 net.cpp:84] Creating Layer conv2_1
I0318 20:19:51.175540  5933 net.cpp:406] conv2_1 <- pool1
I0318 20:19:51.175546  5933 net.cpp:380] conv2_1 -> conv2_1
I0318 20:19:51.177770  5933 net.cpp:122] Setting up conv2_1
I0318 20:19:51.177788  5933 net.cpp:129] Top shape: 25 128 112 112 (40140800)
I0318 20:19:51.177793  5933 net.cpp:137] Memory required for data: 1540403300
I0318 20:19:51.177834  5933 layer_factory.hpp:77] Creating layer relu2_1
I0318 20:19:51.177841  5933 net.cpp:84] Creating Layer relu2_1
I0318 20:19:51.177845  5933 net.cpp:406] relu2_1 <- conv2_1
I0318 20:19:51.177850  5933 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0318 20:19:51.178036  5933 net.cpp:122] Setting up relu2_1
I0318 20:19:51.178050  5933 net.cpp:129] Top shape: 25 128 112 112 (40140800)
I0318 20:19:51.178053  5933 net.cpp:137] Memory required for data: 1700966500
I0318 20:19:51.178058  5933 layer_factory.hpp:77] Creating layer conv2_2
I0318 20:19:51.178071  5933 net.cpp:84] Creating Layer conv2_2
I0318 20:19:51.178076  5933 net.cpp:406] conv2_2 <- conv2_1
I0318 20:19:51.178082  5933 net.cpp:380] conv2_2 -> conv2_2
I0318 20:19:51.179486  5933 net.cpp:122] Setting up conv2_2
I0318 20:19:51.179503  5933 net.cpp:129] Top shape: 25 128 112 112 (40140800)
I0318 20:19:51.179507  5933 net.cpp:137] Memory required for data: 1861529700
I0318 20:19:51.179514  5933 layer_factory.hpp:77] Creating layer relu2_2
I0318 20:19:51.179520  5933 net.cpp:84] Creating Layer relu2_2
I0318 20:19:51.179523  5933 net.cpp:406] relu2_2 <- conv2_2
I0318 20:19:51.179529  5933 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0318 20:19:51.179721  5933 net.cpp:122] Setting up relu2_2
I0318 20:19:51.179734  5933 net.cpp:129] Top shape: 25 128 112 112 (40140800)
I0318 20:19:51.179738  5933 net.cpp:137] Memory required for data: 2022092900
I0318 20:19:51.179744  5933 layer_factory.hpp:77] Creating layer pool2
I0318 20:19:51.179752  5933 net.cpp:84] Creating Layer pool2
I0318 20:19:51.179756  5933 net.cpp:406] pool2 <- conv2_2
I0318 20:19:51.179762  5933 net.cpp:380] pool2 -> pool2
I0318 20:19:51.179811  5933 net.cpp:122] Setting up pool2
I0318 20:19:51.179818  5933 net.cpp:129] Top shape: 25 128 56 56 (10035200)
I0318 20:19:51.179821  5933 net.cpp:137] Memory required for data: 2062233700
I0318 20:19:51.179824  5933 layer_factory.hpp:77] Creating layer conv3_1
I0318 20:19:51.179833  5933 net.cpp:84] Creating Layer conv3_1
I0318 20:19:51.179838  5933 net.cpp:406] conv3_1 <- pool2
I0318 20:19:51.179843  5933 net.cpp:380] conv3_1 -> conv3_1
I0318 20:19:51.182361  5933 net.cpp:122] Setting up conv3_1
I0318 20:19:51.182379  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.182382  5933 net.cpp:137] Memory required for data: 2142515300
I0318 20:19:51.182394  5933 layer_factory.hpp:77] Creating layer relu3_1
I0318 20:19:51.182402  5933 net.cpp:84] Creating Layer relu3_1
I0318 20:19:51.182405  5933 net.cpp:406] relu3_1 <- conv3_1
I0318 20:19:51.182410  5933 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0318 20:19:51.182811  5933 net.cpp:122] Setting up relu3_1
I0318 20:19:51.182826  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.182831  5933 net.cpp:137] Memory required for data: 2222796900
I0318 20:19:51.182833  5933 layer_factory.hpp:77] Creating layer conv3_2
I0318 20:19:51.182842  5933 net.cpp:84] Creating Layer conv3_2
I0318 20:19:51.182845  5933 net.cpp:406] conv3_2 <- conv3_1
I0318 20:19:51.182852  5933 net.cpp:380] conv3_2 -> conv3_2
I0318 20:19:51.185514  5933 net.cpp:122] Setting up conv3_2
I0318 20:19:51.185533  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.185536  5933 net.cpp:137] Memory required for data: 2303078500
I0318 20:19:51.185544  5933 layer_factory.hpp:77] Creating layer relu3_2
I0318 20:19:51.185549  5933 net.cpp:84] Creating Layer relu3_2
I0318 20:19:51.185554  5933 net.cpp:406] relu3_2 <- conv3_2
I0318 20:19:51.185559  5933 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0318 20:19:51.185951  5933 net.cpp:122] Setting up relu3_2
I0318 20:19:51.185967  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.185971  5933 net.cpp:137] Memory required for data: 2383360100
I0318 20:19:51.185974  5933 layer_factory.hpp:77] Creating layer conv3_3
I0318 20:19:51.185983  5933 net.cpp:84] Creating Layer conv3_3
I0318 20:19:51.185986  5933 net.cpp:406] conv3_3 <- conv3_2
I0318 20:19:51.185992  5933 net.cpp:380] conv3_3 -> conv3_3
I0318 20:19:51.188849  5933 net.cpp:122] Setting up conv3_3
I0318 20:19:51.188884  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.188889  5933 net.cpp:137] Memory required for data: 2463641700
I0318 20:19:51.188895  5933 layer_factory.hpp:77] Creating layer relu3_3
I0318 20:19:51.188904  5933 net.cpp:84] Creating Layer relu3_3
I0318 20:19:51.188907  5933 net.cpp:406] relu3_3 <- conv3_3
I0318 20:19:51.188912  5933 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0318 20:19:51.189110  5933 net.cpp:122] Setting up relu3_3
I0318 20:19:51.189123  5933 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0318 20:19:51.189126  5933 net.cpp:137] Memory required for data: 2543923300
I0318 20:19:51.189131  5933 layer_factory.hpp:77] Creating layer pool3
I0318 20:19:51.189141  5933 net.cpp:84] Creating Layer pool3
I0318 20:19:51.189143  5933 net.cpp:406] pool3 <- conv3_3
I0318 20:19:51.189148  5933 net.cpp:380] pool3 -> pool3
I0318 20:19:51.189198  5933 net.cpp:122] Setting up pool3
I0318 20:19:51.189208  5933 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0318 20:19:51.189210  5933 net.cpp:137] Memory required for data: 2563993700
I0318 20:19:51.189213  5933 layer_factory.hpp:77] Creating layer conv4_1_local_channel
I0318 20:19:51.189225  5933 net.cpp:84] Creating Layer conv4_1_local_channel
I0318 20:19:51.189229  5933 net.cpp:406] conv4_1_local_channel <- pool3
I0318 20:19:51.189236  5933 net.cpp:380] conv4_1_local_channel -> conv4_1
I0318 20:19:51.243187  5933 net.cpp:122] Setting up conv4_1_local_channel
I0318 20:19:51.243206  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.243211  5933 net.cpp:137] Memory required for data: 2604134500
I0318 20:19:51.243217  5933 layer_factory.hpp:77] Creating layer relu4_1
I0318 20:19:51.243223  5933 net.cpp:84] Creating Layer relu4_1
I0318 20:19:51.243227  5933 net.cpp:406] relu4_1 <- conv4_1
I0318 20:19:51.243234  5933 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0318 20:19:51.243484  5933 net.cpp:122] Setting up relu4_1
I0318 20:19:51.243499  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.243502  5933 net.cpp:137] Memory required for data: 2644275300
I0318 20:19:51.243508  5933 layer_factory.hpp:77] Creating layer conv4_2_local_channel
I0318 20:19:51.243525  5933 net.cpp:84] Creating Layer conv4_2_local_channel
I0318 20:19:51.243533  5933 net.cpp:406] conv4_2_local_channel <- conv4_1
I0318 20:19:51.243541  5933 net.cpp:380] conv4_2_local_channel -> conv4_2
I0318 20:19:51.395247  5933 net.cpp:122] Setting up conv4_2_local_channel
I0318 20:19:51.395319  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.395328  5933 net.cpp:137] Memory required for data: 2684416100
I0318 20:19:51.395352  5933 layer_factory.hpp:77] Creating layer relu4_2
I0318 20:19:51.395370  5933 net.cpp:84] Creating Layer relu4_2
I0318 20:19:51.395381  5933 net.cpp:406] relu4_2 <- conv4_2
I0318 20:19:51.395391  5933 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0318 20:19:51.395787  5933 net.cpp:122] Setting up relu4_2
I0318 20:19:51.395805  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.395809  5933 net.cpp:137] Memory required for data: 2724556900
I0318 20:19:51.395814  5933 layer_factory.hpp:77] Creating layer conv4_3_pointwise
I0318 20:19:51.395835  5933 net.cpp:84] Creating Layer conv4_3_pointwise
I0318 20:19:51.395841  5933 net.cpp:406] conv4_3_pointwise <- conv4_2
I0318 20:19:51.395853  5933 net.cpp:380] conv4_3_pointwise -> conv4_3
I0318 20:19:51.402132  5933 net.cpp:122] Setting up conv4_3_pointwise
I0318 20:19:51.402159  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.402165  5933 net.cpp:137] Memory required for data: 2764697700
I0318 20:19:51.402175  5933 layer_factory.hpp:77] Creating layer relu4_3
I0318 20:19:51.402189  5933 net.cpp:84] Creating Layer relu4_3
I0318 20:19:51.402194  5933 net.cpp:406] relu4_3 <- conv4_3
I0318 20:19:51.402201  5933 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0318 20:19:51.402590  5933 net.cpp:122] Setting up relu4_3
I0318 20:19:51.402609  5933 net.cpp:129] Top shape: 25 512 28 28 (10035200)
I0318 20:19:51.402613  5933 net.cpp:137] Memory required for data: 2804838500
I0318 20:19:51.402653  5933 layer_factory.hpp:77] Creating layer pool4
I0318 20:19:51.402667  5933 net.cpp:84] Creating Layer pool4
I0318 20:19:51.402671  5933 net.cpp:406] pool4 <- conv4_3
I0318 20:19:51.402683  5933 net.cpp:380] pool4 -> pool4
I0318 20:19:51.402804  5933 net.cpp:122] Setting up pool4
I0318 20:19:51.402817  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.402822  5933 net.cpp:137] Memory required for data: 2814873700
I0318 20:19:51.402825  5933 layer_factory.hpp:77] Creating layer conv5_1_local_channel
I0318 20:19:51.402842  5933 net.cpp:84] Creating Layer conv5_1_local_channel
I0318 20:19:51.402850  5933 net.cpp:406] conv5_1_local_channel <- pool4
I0318 20:19:51.402863  5933 net.cpp:380] conv5_1_local_channel -> conv5_1
I0318 20:19:51.591126  5933 net.cpp:122] Setting up conv5_1_local_channel
I0318 20:19:51.591171  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.591176  5933 net.cpp:137] Memory required for data: 2824908900
I0318 20:19:51.591205  5933 layer_factory.hpp:77] Creating layer relu5_1
I0318 20:19:51.591233  5933 net.cpp:84] Creating Layer relu5_1
I0318 20:19:51.591238  5933 net.cpp:406] relu5_1 <- conv5_1
I0318 20:19:51.591243  5933 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0318 20:19:51.591569  5933 net.cpp:122] Setting up relu5_1
I0318 20:19:51.591584  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.591588  5933 net.cpp:137] Memory required for data: 2834944100
I0318 20:19:51.591591  5933 layer_factory.hpp:77] Creating layer conv5_2_local_channel
I0318 20:19:51.591619  5933 net.cpp:84] Creating Layer conv5_2_local_channel
I0318 20:19:51.591624  5933 net.cpp:406] conv5_2_local_channel <- conv5_1
I0318 20:19:51.591632  5933 net.cpp:380] conv5_2_local_channel -> conv5_2
I0318 20:19:51.730988  5933 net.cpp:122] Setting up conv5_2_local_channel
I0318 20:19:51.731014  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.731019  5933 net.cpp:137] Memory required for data: 2844979300
I0318 20:19:51.731026  5933 layer_factory.hpp:77] Creating layer relu5_2
I0318 20:19:51.731041  5933 net.cpp:84] Creating Layer relu5_2
I0318 20:19:51.731047  5933 net.cpp:406] relu5_2 <- conv5_2
I0318 20:19:51.731052  5933 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0318 20:19:51.731302  5933 net.cpp:122] Setting up relu5_2
I0318 20:19:51.731317  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.731320  5933 net.cpp:137] Memory required for data: 2855014500
I0318 20:19:51.731323  5933 layer_factory.hpp:77] Creating layer conv5_3_pointwise
I0318 20:19:51.731335  5933 net.cpp:84] Creating Layer conv5_3_pointwise
I0318 20:19:51.731340  5933 net.cpp:406] conv5_3_pointwise <- conv5_2
I0318 20:19:51.731355  5933 net.cpp:380] conv5_3_pointwise -> conv5_3
I0318 20:19:51.735056  5933 net.cpp:122] Setting up conv5_3_pointwise
I0318 20:19:51.735076  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.735080  5933 net.cpp:137] Memory required for data: 2865049700
I0318 20:19:51.735087  5933 layer_factory.hpp:77] Creating layer relu5_3
I0318 20:19:51.735093  5933 net.cpp:84] Creating Layer relu5_3
I0318 20:19:51.735096  5933 net.cpp:406] relu5_3 <- conv5_3
I0318 20:19:51.735103  5933 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0318 20:19:51.735623  5933 net.cpp:122] Setting up relu5_3
I0318 20:19:51.735641  5933 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0318 20:19:51.735643  5933 net.cpp:137] Memory required for data: 2875084900
I0318 20:19:51.735647  5933 layer_factory.hpp:77] Creating layer pool5
I0318 20:19:51.735656  5933 net.cpp:84] Creating Layer pool5
I0318 20:19:51.735661  5933 net.cpp:406] pool5 <- conv5_3
I0318 20:19:51.735672  5933 net.cpp:380] pool5 -> pool5
I0318 20:19:51.735806  5933 net.cpp:122] Setting up pool5
I0318 20:19:51.735817  5933 net.cpp:129] Top shape: 25 512 7 7 (627200)
I0318 20:19:51.735821  5933 net.cpp:137] Memory required for data: 2877593700
I0318 20:19:51.735832  5933 layer_factory.hpp:77] Creating layer fc6
I0318 20:19:51.735860  5933 net.cpp:84] Creating Layer fc6
I0318 20:19:51.735893  5933 net.cpp:406] fc6 <- pool5
I0318 20:19:51.735901  5933 net.cpp:380] fc6 -> fc6
I0318 20:19:52.035393  5933 net.cpp:122] Setting up fc6
I0318 20:19:52.035444  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.035449  5933 net.cpp:137] Memory required for data: 2878003300
I0318 20:19:52.035470  5933 layer_factory.hpp:77] Creating layer relu6
I0318 20:19:52.035481  5933 net.cpp:84] Creating Layer relu6
I0318 20:19:52.035486  5933 net.cpp:406] relu6 <- fc6
I0318 20:19:52.035497  5933 net.cpp:367] relu6 -> fc6 (in-place)
I0318 20:19:52.036015  5933 net.cpp:122] Setting up relu6
I0318 20:19:52.036028  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.036031  5933 net.cpp:137] Memory required for data: 2878412900
I0318 20:19:52.036034  5933 layer_factory.hpp:77] Creating layer drop6
I0318 20:19:52.036046  5933 net.cpp:84] Creating Layer drop6
I0318 20:19:52.036049  5933 net.cpp:406] drop6 <- fc6
I0318 20:19:52.036054  5933 net.cpp:367] drop6 -> fc6 (in-place)
I0318 20:19:52.036167  5933 net.cpp:122] Setting up drop6
I0318 20:19:52.036177  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.036180  5933 net.cpp:137] Memory required for data: 2878822500
I0318 20:19:52.036185  5933 layer_factory.hpp:77] Creating layer fc7
I0318 20:19:52.036193  5933 net.cpp:84] Creating Layer fc7
I0318 20:19:52.036198  5933 net.cpp:406] fc7 <- fc6
I0318 20:19:52.036208  5933 net.cpp:380] fc7 -> fc7
I0318 20:19:52.085577  5933 net.cpp:122] Setting up fc7
I0318 20:19:52.085628  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.085631  5933 net.cpp:137] Memory required for data: 2879232100
I0318 20:19:52.085664  5933 layer_factory.hpp:77] Creating layer relu7
I0318 20:19:52.085678  5933 net.cpp:84] Creating Layer relu7
I0318 20:19:52.085683  5933 net.cpp:406] relu7 <- fc7
I0318 20:19:52.085690  5933 net.cpp:367] relu7 -> fc7 (in-place)
I0318 20:19:52.086014  5933 net.cpp:122] Setting up relu7
I0318 20:19:52.086028  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.086030  5933 net.cpp:137] Memory required for data: 2879641700
I0318 20:19:52.086033  5933 layer_factory.hpp:77] Creating layer drop7
I0318 20:19:52.086042  5933 net.cpp:84] Creating Layer drop7
I0318 20:19:52.086046  5933 net.cpp:406] drop7 <- fc7
I0318 20:19:52.086053  5933 net.cpp:367] drop7 -> fc7 (in-place)
I0318 20:19:52.086130  5933 net.cpp:122] Setting up drop7
I0318 20:19:52.086143  5933 net.cpp:129] Top shape: 25 4096 (102400)
I0318 20:19:52.086145  5933 net.cpp:137] Memory required for data: 2880051300
I0318 20:19:52.086148  5933 layer_factory.hpp:77] Creating layer fc8
I0318 20:19:52.086158  5933 net.cpp:84] Creating Layer fc8
I0318 20:19:52.086160  5933 net.cpp:406] fc8 <- fc7
I0318 20:19:52.086167  5933 net.cpp:380] fc8 -> fc8
I0318 20:19:52.118332  5933 net.cpp:122] Setting up fc8
I0318 20:19:52.118350  5933 net.cpp:129] Top shape: 25 1000 (25000)
I0318 20:19:52.118355  5933 net.cpp:137] Memory required for data: 2880151300
I0318 20:19:52.118361  5933 layer_factory.hpp:77] Creating layer loss
I0318 20:19:52.118378  5933 net.cpp:84] Creating Layer loss
I0318 20:19:52.118382  5933 net.cpp:406] loss <- fc8
I0318 20:19:52.118387  5933 net.cpp:406] loss <- label
I0318 20:19:52.118396  5933 net.cpp:380] loss -> loss/loss
I0318 20:19:52.118413  5933 layer_factory.hpp:77] Creating layer loss
I0318 20:19:52.118995  5933 net.cpp:122] Setting up loss
I0318 20:19:52.119010  5933 net.cpp:129] Top shape: (1)
I0318 20:19:52.119012  5933 net.cpp:132]     with loss weight 1
I0318 20:19:52.119045  5933 net.cpp:137] Memory required for data: 2880151304
I0318 20:19:52.119050  5933 net.cpp:198] loss needs backward computation.
I0318 20:19:52.119057  5933 net.cpp:198] fc8 needs backward computation.
I0318 20:19:52.119060  5933 net.cpp:198] drop7 needs backward computation.
I0318 20:19:52.119063  5933 net.cpp:198] relu7 needs backward computation.
I0318 20:19:52.119065  5933 net.cpp:198] fc7 needs backward computation.
I0318 20:19:52.119068  5933 net.cpp:198] drop6 needs backward computation.
I0318 20:19:52.119105  5933 net.cpp:198] relu6 needs backward computation.
I0318 20:19:52.119110  5933 net.cpp:198] fc6 needs backward computation.
I0318 20:19:52.119117  5933 net.cpp:198] pool5 needs backward computation.
I0318 20:19:52.119122  5933 net.cpp:198] relu5_3 needs backward computation.
I0318 20:19:52.119127  5933 net.cpp:198] conv5_3_pointwise needs backward computation.
I0318 20:19:52.119132  5933 net.cpp:198] relu5_2 needs backward computation.
I0318 20:19:52.119138  5933 net.cpp:198] conv5_2_local_channel needs backward computation.
I0318 20:19:52.119143  5933 net.cpp:198] relu5_1 needs backward computation.
I0318 20:19:52.119148  5933 net.cpp:198] conv5_1_local_channel needs backward computation.
I0318 20:19:52.119163  5933 net.cpp:198] pool4 needs backward computation.
I0318 20:19:52.119173  5933 net.cpp:198] relu4_3 needs backward computation.
I0318 20:19:52.119180  5933 net.cpp:198] conv4_3_pointwise needs backward computation.
I0318 20:19:52.119194  5933 net.cpp:198] relu4_2 needs backward computation.
I0318 20:19:52.119199  5933 net.cpp:198] conv4_2_local_channel needs backward computation.
I0318 20:19:52.119202  5933 net.cpp:198] relu4_1 needs backward computation.
I0318 20:19:52.119207  5933 net.cpp:198] conv4_1_local_channel needs backward computation.
I0318 20:19:52.119212  5933 net.cpp:198] pool3 needs backward computation.
I0318 20:19:52.119217  5933 net.cpp:198] relu3_3 needs backward computation.
I0318 20:19:52.119222  5933 net.cpp:198] conv3_3 needs backward computation.
I0318 20:19:52.119227  5933 net.cpp:198] relu3_2 needs backward computation.
I0318 20:19:52.119232  5933 net.cpp:198] conv3_2 needs backward computation.
I0318 20:19:52.119236  5933 net.cpp:198] relu3_1 needs backward computation.
I0318 20:19:52.119241  5933 net.cpp:198] conv3_1 needs backward computation.
I0318 20:19:52.119246  5933 net.cpp:200] pool2 does not need backward computation.
I0318 20:19:52.119252  5933 net.cpp:200] relu2_2 does not need backward computation.
I0318 20:19:52.119256  5933 net.cpp:200] conv2_2 does not need backward computation.
I0318 20:19:52.119262  5933 net.cpp:200] relu2_1 does not need backward computation.
I0318 20:19:52.119273  5933 net.cpp:200] conv2_1 does not need backward computation.
I0318 20:19:52.119277  5933 net.cpp:200] pool1 does not need backward computation.
I0318 20:19:52.119287  5933 net.cpp:200] relu1_2 does not need backward computation.
I0318 20:19:52.119292  5933 net.cpp:200] conv1_2 does not need backward computation.
I0318 20:19:52.119297  5933 net.cpp:200] relu1_1 does not need backward computation.
I0318 20:19:52.119299  5933 net.cpp:200] conv1_1 does not need backward computation.
I0318 20:19:52.119303  5933 net.cpp:200] data does not need backward computation.
I0318 20:19:52.119307  5933 net.cpp:242] This network produces output loss/loss
I0318 20:19:52.119333  5933 net.cpp:255] Network initialization done.
I0318 20:19:52.119550  5933 solver.cpp:72] Finetuning from models/local_channel_vgg16/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0318 20:19:52.524636  5933 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: models/local_channel_vgg16/VGG16.v2.caffemodel
I0318 20:19:52.524683  5933 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.
W0318 20:19:52.524688  5933 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.
I0318 20:19:52.526312  5933 net.cpp:744] Ignoring source layer conv4_1
I0318 20:19:52.526321  5933 net.cpp:744] Ignoring source layer conv4_2
I0318 20:19:52.526336  5933 net.cpp:744] Ignoring source layer conv4_3
I0318 20:19:52.526340  5933 net.cpp:744] Ignoring source layer conv5_1
I0318 20:19:52.526342  5933 net.cpp:744] Ignoring source layer conv5_2
I0318 20:19:52.526345  5933 net.cpp:744] Ignoring source layer conv5_3
I0318 20:19:52.630638  5933 net.cpp:744] Ignoring source layer prob
I0318 20:19:52.632436  5933 solver.cpp:190] Creating test net (#0) specified by net file: models/local_channel_vgg16/train_val.prototxt
I0318 20:19:52.632503  5933 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0318 20:19:52.632742  5933 net.cpp:51] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/data/ImageNet/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_val_lmdb"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_local_channel"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 8
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2_local_channel"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3_pointwise"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1_local_channel"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2_local_channel"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    force_local_channel: true
    kernel_c: 12
    stride_c: 4
    num_output_per_group: 4
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3_pointwise"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss/loss"
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy@1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy@5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0318 20:19:52.632925  5933 layer_factory.hpp:77] Creating layer data
I0318 20:19:52.633026  5933 db_lmdb.cpp:35] Opened lmdb examples/imagenet/ilsvrc12_val_lmdb
I0318 20:19:52.633054  5933 net.cpp:84] Creating Layer data
I0318 20:19:52.633064  5933 net.cpp:380] data -> data
I0318 20:19:52.633076  5933 net.cpp:380] data -> label
I0318 20:19:52.633085  5933 data_transformer.cpp:25] Loading mean file from: /home/data/ImageNet/data/ilsvrc12/imagenet_mean.binaryproto
I0318 20:19:52.634809  5933 data_layer.cpp:45] output data size: 10,3,224,224
I0318 20:19:52.649231  5933 net.cpp:122] Setting up data
I0318 20:19:52.649253  5933 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0318 20:19:52.649260  5933 net.cpp:129] Top shape: 10 (10)
I0318 20:19:52.649262  5933 net.cpp:137] Memory required for data: 6021160
I0318 20:19:52.649269  5933 layer_factory.hpp:77] Creating layer label_data_1_split
I0318 20:19:52.649292  5933 net.cpp:84] Creating Layer label_data_1_split
I0318 20:19:52.649298  5933 net.cpp:406] label_data_1_split <- label
I0318 20:19:52.649305  5933 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0318 20:19:52.649314  5933 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0318 20:19:52.649319  5933 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0318 20:19:52.649458  5933 net.cpp:122] Setting up label_data_1_split
I0318 20:19:52.649466  5933 net.cpp:129] Top shape: 10 (10)
I0318 20:19:52.649469  5933 net.cpp:129] Top shape: 10 (10)
I0318 20:19:52.649472  5933 net.cpp:129] Top shape: 10 (10)
I0318 20:19:52.649473  5933 net.cpp:137] Memory required for data: 6021280
I0318 20:19:52.649477  5933 layer_factory.hpp:77] Creating layer conv1_1
I0318 20:19:52.649489  5933 net.cpp:84] Creating Layer conv1_1
I0318 20:19:52.649492  5933 net.cpp:406] conv1_1 <- data
I0318 20:19:52.649497  5933 net.cpp:380] conv1_1 -> conv1_1
I0318 20:19:52.654384  5933 net.cpp:122] Setting up conv1_1
I0318 20:19:52.654422  5933 net.cpp:129] Top shape: 10 64 224 224 (32112640)
I0318 20:19:52.654431  5933 net.cpp:137] Memory required for data: 134471840
I0318 20:19:52.654455  5933 layer_factory.hpp:77] Creating layer relu1_1
I0318 20:19:52.654470  5933 net.cpp:84] Creating Layer relu1_1
I0318 20:19:52.654479  5933 net.cpp:406] relu1_1 <- conv1_1
I0318 20:19:52.654495  5933 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0318 20:19:52.655473  5933 net.cpp:122] Setting up relu1_1
I0318 20:19:52.655508  5933 net.cpp:129] Top shape: 10 64 224 224 (32112640)
I0318 20:19:52.655515  5933 net.cpp:137] Memory required for data: 262922400
I0318 20:19:52.655522  5933 layer_factory.hpp:77] Creating layer conv1_2
I0318 20:19:52.655544  5933 net.cpp:84] Creating Layer conv1_2
I0318 20:19:52.655552  5933 net.cpp:406] conv1_2 <- conv1_1
I0318 20:19:52.655565  5933 net.cpp:380] conv1_2 -> conv1_2
I0318 20:19:52.658370  5933 net.cpp:122] Setting up conv1_2
I0318 20:19:52.658398  5933 net.cpp:129] Top shape: 10 64 224 224 (32112640)
I0318 20:19:52.658406  5933 net.cpp:137] Memory required for data: 391372960
I0318 20:19:52.658423  5933 layer_factory.hpp:77] Creating layer relu1_2
I0318 20:19:52.658437  5933 net.cpp:84] Creating Layer relu1_2
I0318 20:19:52.658444  5933 net.cpp:406] relu1_2 <- conv1_2
I0318 20:19:52.658455  5933 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0318 20:19:52.659441  5933 net.cpp:122] Setting up relu1_2
I0318 20:19:52.659474  5933 net.cpp:129] Top shape: 10 64 224 224 (32112640)
I0318 20:19:52.659482  5933 net.cpp:137] Memory required for data: 519823520
I0318 20:19:52.659488  5933 layer_factory.hpp:77] Creating layer pool1
I0318 20:19:52.659502  5933 net.cpp:84] Creating Layer pool1
I0318 20:19:52.659509  5933 net.cpp:406] pool1 <- conv1_2
I0318 20:19:52.659523  5933 net.cpp:380] pool1 -> pool1
I0318 20:19:52.659729  5933 net.cpp:122] Setting up pool1
I0318 20:19:52.659749  5933 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0318 20:19:52.659757  5933 net.cpp:137] Memory required for data: 551936160
I0318 20:19:52.659763  5933 layer_factory.hpp:77] Creating layer conv2_1
I0318 20:19:52.659780  5933 net.cpp:84] Creating Layer conv2_1
I0318 20:19:52.659787  5933 net.cpp:406] conv2_1 <- pool1
I0318 20:19:52.659806  5933 net.cpp:380] conv2_1 -> conv2_1
I0318 20:19:52.663224  5933 net.cpp:122] Setting up conv2_1
I0318 20:19:52.663256  5933 net.cpp:129] Top shape: 10 128 112 112 (16056320)
I0318 20:19:52.663264  5933 net.cpp:137] Memory required for data: 616161440
I0318 20:19:52.663301  5933 layer_factory.hpp:77] Creating layer relu2_1
I0318 20:19:52.663362  5933 net.cpp:84] Creating Layer relu2_1
I0318 20:19:52.663374  5933 net.cpp:406] relu2_1 <- conv2_1
I0318 20:19:52.663385  5933 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0318 20:19:52.664368  5933 net.cpp:122] Setting up relu2_1
I0318 20:19:52.664392  5933 net.cpp:129] Top shape: 10 128 112 112 (16056320)
I0318 20:19:52.664398  5933 net.cpp:137] Memory required for data: 680386720
I0318 20:19:52.664405  5933 layer_factory.hpp:77] Creating layer conv2_2
I0318 20:19:52.664422  5933 net.cpp:84] Creating Layer conv2_2
I0318 20:19:52.664429  5933 net.cpp:406] conv2_2 <- conv2_1
I0318 20:19:52.664441  5933 net.cpp:380] conv2_2 -> conv2_2
I0318 20:19:52.669543  5933 net.cpp:122] Setting up conv2_2
I0318 20:19:52.669576  5933 net.cpp:129] Top shape: 10 128 112 112 (16056320)
I0318 20:19:52.669584  5933 net.cpp:137] Memory required for data: 744612000
I0318 20:19:52.669597  5933 layer_factory.hpp:77] Creating layer relu2_2
I0318 20:19:52.669610  5933 net.cpp:84] Creating Layer relu2_2
I0318 20:19:52.669616  5933 net.cpp:406] relu2_2 <- conv2_2
I0318 20:19:52.669626  5933 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0318 20:19:52.670065  5933 net.cpp:122] Setting up relu2_2
I0318 20:19:52.670087  5933 net.cpp:129] Top shape: 10 128 112 112 (16056320)
I0318 20:19:52.670094  5933 net.cpp:137] Memory required for data: 808837280
I0318 20:19:52.670099  5933 layer_factory.hpp:77] Creating layer pool2
I0318 20:19:52.670111  5933 net.cpp:84] Creating Layer pool2
I0318 20:19:52.670119  5933 net.cpp:406] pool2 <- conv2_2
I0318 20:19:52.670130  5933 net.cpp:380] pool2 -> pool2
I0318 20:19:52.670321  5933 net.cpp:122] Setting up pool2
I0318 20:19:52.670339  5933 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0318 20:19:52.670344  5933 net.cpp:137] Memory required for data: 824893600
I0318 20:19:52.670351  5933 layer_factory.hpp:77] Creating layer conv3_1
I0318 20:19:52.670366  5933 net.cpp:84] Creating Layer conv3_1
I0318 20:19:52.670373  5933 net.cpp:406] conv3_1 <- pool2
I0318 20:19:52.670413  5933 net.cpp:380] conv3_1 -> conv3_1
I0318 20:19:52.675159  5933 net.cpp:122] Setting up conv3_1
I0318 20:19:52.675190  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.675196  5933 net.cpp:137] Memory required for data: 857006240
I0318 20:19:52.675217  5933 layer_factory.hpp:77] Creating layer relu3_1
I0318 20:19:52.675230  5933 net.cpp:84] Creating Layer relu3_1
I0318 20:19:52.675237  5933 net.cpp:406] relu3_1 <- conv3_1
I0318 20:19:52.675252  5933 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0318 20:19:52.675686  5933 net.cpp:122] Setting up relu3_1
I0318 20:19:52.675709  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.675715  5933 net.cpp:137] Memory required for data: 889118880
I0318 20:19:52.675721  5933 layer_factory.hpp:77] Creating layer conv3_2
I0318 20:19:52.675739  5933 net.cpp:84] Creating Layer conv3_2
I0318 20:19:52.675745  5933 net.cpp:406] conv3_2 <- conv3_1
I0318 20:19:52.675757  5933 net.cpp:380] conv3_2 -> conv3_2
I0318 20:19:52.681774  5933 net.cpp:122] Setting up conv3_2
I0318 20:19:52.681802  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.681809  5933 net.cpp:137] Memory required for data: 921231520
I0318 20:19:52.681821  5933 layer_factory.hpp:77] Creating layer relu3_2
I0318 20:19:52.681833  5933 net.cpp:84] Creating Layer relu3_2
I0318 20:19:52.681839  5933 net.cpp:406] relu3_2 <- conv3_2
I0318 20:19:52.681849  5933 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0318 20:19:52.682246  5933 net.cpp:122] Setting up relu3_2
I0318 20:19:52.682267  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.682272  5933 net.cpp:137] Memory required for data: 953344160
I0318 20:19:52.682278  5933 layer_factory.hpp:77] Creating layer conv3_3
I0318 20:19:52.682296  5933 net.cpp:84] Creating Layer conv3_3
I0318 20:19:52.682303  5933 net.cpp:406] conv3_3 <- conv3_2
I0318 20:19:52.682315  5933 net.cpp:380] conv3_3 -> conv3_3
I0318 20:19:52.687886  5933 net.cpp:122] Setting up conv3_3
I0318 20:19:52.687911  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.687939  5933 net.cpp:137] Memory required for data: 985456800
I0318 20:19:52.687952  5933 layer_factory.hpp:77] Creating layer relu3_3
I0318 20:19:52.687961  5933 net.cpp:84] Creating Layer relu3_3
I0318 20:19:52.687966  5933 net.cpp:406] relu3_3 <- conv3_3
I0318 20:19:52.687973  5933 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0318 20:19:52.688663  5933 net.cpp:122] Setting up relu3_3
I0318 20:19:52.688681  5933 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0318 20:19:52.688685  5933 net.cpp:137] Memory required for data: 1017569440
I0318 20:19:52.688689  5933 layer_factory.hpp:77] Creating layer pool3
I0318 20:19:52.688699  5933 net.cpp:84] Creating Layer pool3
I0318 20:19:52.688704  5933 net.cpp:406] pool3 <- conv3_3
I0318 20:19:52.688712  5933 net.cpp:380] pool3 -> pool3
I0318 20:19:52.688851  5933 net.cpp:122] Setting up pool3
I0318 20:19:52.688863  5933 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0318 20:19:52.688866  5933 net.cpp:137] Memory required for data: 1025597600
I0318 20:19:52.688870  5933 layer_factory.hpp:77] Creating layer conv4_1_local_channel
I0318 20:19:52.688884  5933 net.cpp:84] Creating Layer conv4_1_local_channel
I0318 20:19:52.688890  5933 net.cpp:406] conv4_1_local_channel <- pool3
I0318 20:19:52.688897  5933 net.cpp:380] conv4_1_local_channel -> conv4_1
I0318 20:19:52.777645  5933 net.cpp:122] Setting up conv4_1_local_channel
I0318 20:19:52.777681  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.777688  5933 net.cpp:137] Memory required for data: 1041653920
I0318 20:19:52.777704  5933 layer_factory.hpp:77] Creating layer relu4_1
I0318 20:19:52.777716  5933 net.cpp:84] Creating Layer relu4_1
I0318 20:19:52.777724  5933 net.cpp:406] relu4_1 <- conv4_1
I0318 20:19:52.777735  5933 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0318 20:19:52.778172  5933 net.cpp:122] Setting up relu4_1
I0318 20:19:52.778194  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.778201  5933 net.cpp:137] Memory required for data: 1057710240
I0318 20:19:52.778208  5933 layer_factory.hpp:77] Creating layer conv4_2_local_channel
I0318 20:19:52.778226  5933 net.cpp:84] Creating Layer conv4_2_local_channel
I0318 20:19:52.778234  5933 net.cpp:406] conv4_2_local_channel <- conv4_1
I0318 20:19:52.778247  5933 net.cpp:380] conv4_2_local_channel -> conv4_2
I0318 20:19:52.978698  5933 net.cpp:122] Setting up conv4_2_local_channel
I0318 20:19:52.978736  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.978744  5933 net.cpp:137] Memory required for data: 1073766560
I0318 20:19:52.978770  5933 layer_factory.hpp:77] Creating layer relu4_2
I0318 20:19:52.978785  5933 net.cpp:84] Creating Layer relu4_2
I0318 20:19:52.978796  5933 net.cpp:406] relu4_2 <- conv4_2
I0318 20:19:52.978806  5933 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0318 20:19:52.979300  5933 net.cpp:122] Setting up relu4_2
I0318 20:19:52.979326  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.979331  5933 net.cpp:137] Memory required for data: 1089822880
I0318 20:19:52.979337  5933 layer_factory.hpp:77] Creating layer conv4_3_pointwise
I0318 20:19:52.979359  5933 net.cpp:84] Creating Layer conv4_3_pointwise
I0318 20:19:52.979367  5933 net.cpp:406] conv4_3_pointwise <- conv4_2
I0318 20:19:52.979382  5933 net.cpp:380] conv4_3_pointwise -> conv4_3
I0318 20:19:52.987828  5933 net.cpp:122] Setting up conv4_3_pointwise
I0318 20:19:52.987862  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.987869  5933 net.cpp:137] Memory required for data: 1105879200
I0318 20:19:52.987882  5933 layer_factory.hpp:77] Creating layer relu4_3
I0318 20:19:52.987895  5933 net.cpp:84] Creating Layer relu4_3
I0318 20:19:52.987902  5933 net.cpp:406] relu4_3 <- conv4_3
I0318 20:19:52.987913  5933 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0318 20:19:52.988365  5933 net.cpp:122] Setting up relu4_3
I0318 20:19:52.988386  5933 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0318 20:19:52.988391  5933 net.cpp:137] Memory required for data: 1121935520
I0318 20:19:52.988397  5933 layer_factory.hpp:77] Creating layer pool4
I0318 20:19:52.988451  5933 net.cpp:84] Creating Layer pool4
I0318 20:19:52.988463  5933 net.cpp:406] pool4 <- conv4_3
I0318 20:19:52.988474  5933 net.cpp:380] pool4 -> pool4
I0318 20:19:52.988731  5933 net.cpp:122] Setting up pool4
I0318 20:19:52.988749  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:52.988754  5933 net.cpp:137] Memory required for data: 1125949600
I0318 20:19:52.988760  5933 layer_factory.hpp:77] Creating layer conv5_1_local_channel
I0318 20:19:52.988780  5933 net.cpp:84] Creating Layer conv5_1_local_channel
I0318 20:19:52.988787  5933 net.cpp:406] conv5_1_local_channel <- pool4
I0318 20:19:52.988800  5933 net.cpp:380] conv5_1_local_channel -> conv5_1
I0318 20:19:53.188171  5933 net.cpp:122] Setting up conv5_1_local_channel
I0318 20:19:53.188215  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.188222  5933 net.cpp:137] Memory required for data: 1129963680
I0318 20:19:53.188239  5933 layer_factory.hpp:77] Creating layer relu5_1
I0318 20:19:53.188254  5933 net.cpp:84] Creating Layer relu5_1
I0318 20:19:53.188263  5933 net.cpp:406] relu5_1 <- conv5_1
I0318 20:19:53.188274  5933 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0318 20:19:53.188776  5933 net.cpp:122] Setting up relu5_1
I0318 20:19:53.188797  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.188803  5933 net.cpp:137] Memory required for data: 1133977760
I0318 20:19:53.188810  5933 layer_factory.hpp:77] Creating layer conv5_2_local_channel
I0318 20:19:53.188833  5933 net.cpp:84] Creating Layer conv5_2_local_channel
I0318 20:19:53.188840  5933 net.cpp:406] conv5_2_local_channel <- conv5_1
I0318 20:19:53.188854  5933 net.cpp:380] conv5_2_local_channel -> conv5_2
I0318 20:19:53.430755  5933 net.cpp:122] Setting up conv5_2_local_channel
I0318 20:19:53.430801  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.430809  5933 net.cpp:137] Memory required for data: 1137991840
I0318 20:19:53.430824  5933 layer_factory.hpp:77] Creating layer relu5_2
I0318 20:19:53.430840  5933 net.cpp:84] Creating Layer relu5_2
I0318 20:19:53.430848  5933 net.cpp:406] relu5_2 <- conv5_2
I0318 20:19:53.430860  5933 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0318 20:19:53.431305  5933 net.cpp:122] Setting up relu5_2
I0318 20:19:53.431334  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.431339  5933 net.cpp:137] Memory required for data: 1142005920
I0318 20:19:53.431346  5933 layer_factory.hpp:77] Creating layer conv5_3_pointwise
I0318 20:19:53.431367  5933 net.cpp:84] Creating Layer conv5_3_pointwise
I0318 20:19:53.431375  5933 net.cpp:406] conv5_3_pointwise <- conv5_2
I0318 20:19:53.431388  5933 net.cpp:380] conv5_3_pointwise -> conv5_3
I0318 20:19:53.439249  5933 net.cpp:122] Setting up conv5_3_pointwise
I0318 20:19:53.439297  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.439304  5933 net.cpp:137] Memory required for data: 1146020000
I0318 20:19:53.439319  5933 layer_factory.hpp:77] Creating layer relu5_3
I0318 20:19:53.439333  5933 net.cpp:84] Creating Layer relu5_3
I0318 20:19:53.439342  5933 net.cpp:406] relu5_3 <- conv5_3
I0318 20:19:53.439352  5933 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0318 20:19:53.439795  5933 net.cpp:122] Setting up relu5_3
I0318 20:19:53.439819  5933 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0318 20:19:53.439826  5933 net.cpp:137] Memory required for data: 1150034080
I0318 20:19:53.439832  5933 layer_factory.hpp:77] Creating layer pool5
I0318 20:19:53.439857  5933 net.cpp:84] Creating Layer pool5
I0318 20:19:53.439869  5933 net.cpp:406] pool5 <- conv5_3
I0318 20:19:53.439887  5933 net.cpp:380] pool5 -> pool5
I0318 20:19:53.440261  5933 net.cpp:122] Setting up pool5
I0318 20:19:53.440284  5933 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0318 20:19:53.440289  5933 net.cpp:137] Memory required for data: 1151037600
I0318 20:19:53.440294  5933 layer_factory.hpp:77] Creating layer fc6
I0318 20:19:53.440310  5933 net.cpp:84] Creating Layer fc6
I0318 20:19:53.440317  5933 net.cpp:406] fc6 <- pool5
I0318 20:19:53.440387  5933 net.cpp:380] fc6 -> fc6
I0318 20:19:53.774893  5933 net.cpp:122] Setting up fc6
I0318 20:19:53.774941  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.774945  5933 net.cpp:137] Memory required for data: 1151201440
I0318 20:19:53.774961  5933 layer_factory.hpp:77] Creating layer relu6
I0318 20:19:53.774977  5933 net.cpp:84] Creating Layer relu6
I0318 20:19:53.774982  5933 net.cpp:406] relu6 <- fc6
I0318 20:19:53.774992  5933 net.cpp:367] relu6 -> fc6 (in-place)
I0318 20:19:53.775347  5933 net.cpp:122] Setting up relu6
I0318 20:19:53.775362  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.775363  5933 net.cpp:137] Memory required for data: 1151365280
I0318 20:19:53.775367  5933 layer_factory.hpp:77] Creating layer drop6
I0318 20:19:53.775377  5933 net.cpp:84] Creating Layer drop6
I0318 20:19:53.775382  5933 net.cpp:406] drop6 <- fc6
I0318 20:19:53.775388  5933 net.cpp:367] drop6 -> fc6 (in-place)
I0318 20:19:53.775506  5933 net.cpp:122] Setting up drop6
I0318 20:19:53.775516  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.775518  5933 net.cpp:137] Memory required for data: 1151529120
I0318 20:19:53.775521  5933 layer_factory.hpp:77] Creating layer fc7
I0318 20:19:53.775533  5933 net.cpp:84] Creating Layer fc7
I0318 20:19:53.775537  5933 net.cpp:406] fc7 <- fc6
I0318 20:19:53.775544  5933 net.cpp:380] fc7 -> fc7
I0318 20:19:53.825287  5933 net.cpp:122] Setting up fc7
I0318 20:19:53.825335  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.825340  5933 net.cpp:137] Memory required for data: 1151692960
I0318 20:19:53.825352  5933 layer_factory.hpp:77] Creating layer relu7
I0318 20:19:53.825366  5933 net.cpp:84] Creating Layer relu7
I0318 20:19:53.825371  5933 net.cpp:406] relu7 <- fc7
I0318 20:19:53.825379  5933 net.cpp:367] relu7 -> fc7 (in-place)
I0318 20:19:53.826797  5933 net.cpp:122] Setting up relu7
I0318 20:19:53.826829  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.826836  5933 net.cpp:137] Memory required for data: 1151856800
I0318 20:19:53.826843  5933 layer_factory.hpp:77] Creating layer drop7
I0318 20:19:53.826858  5933 net.cpp:84] Creating Layer drop7
I0318 20:19:53.826866  5933 net.cpp:406] drop7 <- fc7
I0318 20:19:53.826879  5933 net.cpp:367] drop7 -> fc7 (in-place)
I0318 20:19:53.827070  5933 net.cpp:122] Setting up drop7
I0318 20:19:53.827086  5933 net.cpp:129] Top shape: 10 4096 (40960)
I0318 20:19:53.827092  5933 net.cpp:137] Memory required for data: 1152020640
I0318 20:19:53.827098  5933 layer_factory.hpp:77] Creating layer fc8
I0318 20:19:53.827114  5933 net.cpp:84] Creating Layer fc8
I0318 20:19:53.827123  5933 net.cpp:406] fc8 <- fc7
I0318 20:19:53.827136  5933 net.cpp:380] fc8 -> fc8
I0318 20:19:53.881654  5933 net.cpp:122] Setting up fc8
I0318 20:19:53.881682  5933 net.cpp:129] Top shape: 10 1000 (10000)
I0318 20:19:53.881687  5933 net.cpp:137] Memory required for data: 1152060640
I0318 20:19:53.881700  5933 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0318 20:19:53.881769  5933 net.cpp:84] Creating Layer fc8_fc8_0_split
I0318 20:19:53.881805  5933 net.cpp:406] fc8_fc8_0_split <- fc8
I0318 20:19:53.881821  5933 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0318 20:19:53.881842  5933 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0318 20:19:53.881863  5933 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0318 20:19:53.882323  5933 net.cpp:122] Setting up fc8_fc8_0_split
I0318 20:19:53.882341  5933 net.cpp:129] Top shape: 10 1000 (10000)
I0318 20:19:53.882349  5933 net.cpp:129] Top shape: 10 1000 (10000)
I0318 20:19:53.882355  5933 net.cpp:129] Top shape: 10 1000 (10000)
I0318 20:19:53.882360  5933 net.cpp:137] Memory required for data: 1152180640
I0318 20:19:53.882366  5933 layer_factory.hpp:77] Creating layer loss
I0318 20:19:53.882380  5933 net.cpp:84] Creating Layer loss
I0318 20:19:53.882387  5933 net.cpp:406] loss <- fc8_fc8_0_split_0
I0318 20:19:53.882396  5933 net.cpp:406] loss <- label_data_1_split_0
I0318 20:19:53.882407  5933 net.cpp:380] loss -> loss/loss
I0318 20:19:53.882426  5933 layer_factory.hpp:77] Creating layer loss
I0318 20:19:53.883844  5933 net.cpp:122] Setting up loss
I0318 20:19:53.883870  5933 net.cpp:129] Top shape: (1)
I0318 20:19:53.883877  5933 net.cpp:132]     with loss weight 1
I0318 20:19:53.883895  5933 net.cpp:137] Memory required for data: 1152180644
I0318 20:19:53.883903  5933 layer_factory.hpp:77] Creating layer accuracy/top1
I0318 20:19:53.883936  5933 net.cpp:84] Creating Layer accuracy/top1
I0318 20:19:53.883947  5933 net.cpp:406] accuracy/top1 <- fc8_fc8_0_split_1
I0318 20:19:53.883957  5933 net.cpp:406] accuracy/top1 <- label_data_1_split_1
I0318 20:19:53.883968  5933 net.cpp:380] accuracy/top1 -> accuracy@1
I0318 20:19:53.883991  5933 net.cpp:122] Setting up accuracy/top1
I0318 20:19:53.884001  5933 net.cpp:129] Top shape: (1)
I0318 20:19:53.884006  5933 net.cpp:137] Memory required for data: 1152180648
I0318 20:19:53.884012  5933 layer_factory.hpp:77] Creating layer accuracy/top5
I0318 20:19:53.884021  5933 net.cpp:84] Creating Layer accuracy/top5
I0318 20:19:53.884030  5933 net.cpp:406] accuracy/top5 <- fc8_fc8_0_split_2
I0318 20:19:53.884037  5933 net.cpp:406] accuracy/top5 <- label_data_1_split_2
I0318 20:19:53.884048  5933 net.cpp:380] accuracy/top5 -> accuracy@5
I0318 20:19:53.884060  5933 net.cpp:122] Setting up accuracy/top5
I0318 20:19:53.884070  5933 net.cpp:129] Top shape: (1)
I0318 20:19:53.884075  5933 net.cpp:137] Memory required for data: 1152180652
I0318 20:19:53.884083  5933 net.cpp:200] accuracy/top5 does not need backward computation.
I0318 20:19:53.884091  5933 net.cpp:200] accuracy/top1 does not need backward computation.
I0318 20:19:53.884099  5933 net.cpp:198] loss needs backward computation.
I0318 20:19:53.884109  5933 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0318 20:19:53.884114  5933 net.cpp:198] fc8 needs backward computation.
I0318 20:19:53.884122  5933 net.cpp:198] drop7 needs backward computation.
I0318 20:19:53.884129  5933 net.cpp:198] relu7 needs backward computation.
I0318 20:19:53.884133  5933 net.cpp:198] fc7 needs backward computation.
I0318 20:19:53.884140  5933 net.cpp:198] drop6 needs backward computation.
I0318 20:19:53.884145  5933 net.cpp:198] relu6 needs backward computation.
I0318 20:19:53.884151  5933 net.cpp:198] fc6 needs backward computation.
I0318 20:19:53.884157  5933 net.cpp:198] pool5 needs backward computation.
I0318 20:19:53.884165  5933 net.cpp:198] relu5_3 needs backward computation.
I0318 20:19:53.884174  5933 net.cpp:198] conv5_3_pointwise needs backward computation.
I0318 20:19:53.884181  5933 net.cpp:198] relu5_2 needs backward computation.
I0318 20:19:53.884186  5933 net.cpp:198] conv5_2_local_channel needs backward computation.
I0318 20:19:53.884192  5933 net.cpp:198] relu5_1 needs backward computation.
I0318 20:19:53.884198  5933 net.cpp:198] conv5_1_local_channel needs backward computation.
I0318 20:19:53.884207  5933 net.cpp:198] pool4 needs backward computation.
I0318 20:19:53.884215  5933 net.cpp:198] relu4_3 needs backward computation.
I0318 20:19:53.884222  5933 net.cpp:198] conv4_3_pointwise needs backward computation.
I0318 20:19:53.884227  5933 net.cpp:198] relu4_2 needs backward computation.
I0318 20:19:53.884233  5933 net.cpp:198] conv4_2_local_channel needs backward computation.
I0318 20:19:53.884239  5933 net.cpp:198] relu4_1 needs backward computation.
I0318 20:19:53.884244  5933 net.cpp:198] conv4_1_local_channel needs backward computation.
I0318 20:19:53.884251  5933 net.cpp:198] pool3 needs backward computation.
I0318 20:19:53.884258  5933 net.cpp:198] relu3_3 needs backward computation.
I0318 20:19:53.884263  5933 net.cpp:198] conv3_3 needs backward computation.
I0318 20:19:53.884269  5933 net.cpp:198] relu3_2 needs backward computation.
I0318 20:19:53.884274  5933 net.cpp:198] conv3_2 needs backward computation.
I0318 20:19:53.884281  5933 net.cpp:198] relu3_1 needs backward computation.
I0318 20:19:53.884289  5933 net.cpp:198] conv3_1 needs backward computation.
I0318 20:19:53.884296  5933 net.cpp:200] pool2 does not need backward computation.
I0318 20:19:53.884305  5933 net.cpp:200] relu2_2 does not need backward computation.
I0318 20:19:53.884340  5933 net.cpp:200] conv2_2 does not need backward computation.
I0318 20:19:53.884347  5933 net.cpp:200] relu2_1 does not need backward computation.
I0318 20:19:53.884356  5933 net.cpp:200] conv2_1 does not need backward computation.
I0318 20:19:53.884363  5933 net.cpp:200] pool1 does not need backward computation.
I0318 20:19:53.884372  5933 net.cpp:200] relu1_2 does not need backward computation.
I0318 20:19:53.884379  5933 net.cpp:200] conv1_2 does not need backward computation.
I0318 20:19:53.884387  5933 net.cpp:200] relu1_1 does not need backward computation.
I0318 20:19:53.884392  5933 net.cpp:200] conv1_1 does not need backward computation.
I0318 20:19:53.884402  5933 net.cpp:200] label_data_1_split does not need backward computation.
I0318 20:19:53.884412  5933 net.cpp:200] data does not need backward computation.
I0318 20:19:53.884416  5933 net.cpp:242] This network produces output accuracy@1
I0318 20:19:53.884423  5933 net.cpp:242] This network produces output accuracy@5
I0318 20:19:53.884430  5933 net.cpp:242] This network produces output loss/loss
I0318 20:19:53.884482  5933 net.cpp:255] Network initialization done.
I0318 20:19:53.884693  5933 solver.cpp:72] Finetuning from models/local_channel_vgg16/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0318 20:19:54.340068  5933 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: models/local_channel_vgg16/VGG16.v2.caffemodel
I0318 20:19:54.340093  5933 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.
W0318 20:19:54.340097  5933 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.
I0318 20:19:54.341897  5933 net.cpp:744] Ignoring source layer conv4_1
I0318 20:19:54.341905  5933 net.cpp:744] Ignoring source layer conv4_2
I0318 20:19:54.341908  5933 net.cpp:744] Ignoring source layer conv4_3
I0318 20:19:54.341912  5933 net.cpp:744] Ignoring source layer conv5_1
I0318 20:19:54.341914  5933 net.cpp:744] Ignoring source layer conv5_2
I0318 20:19:54.341917  5933 net.cpp:744] Ignoring source layer conv5_3
I0318 20:19:54.461323  5933 net.cpp:744] Ignoring source layer prob
I0318 20:19:54.463970  5933 solver.cpp:57] Solver scaffolding done.
I0318 20:19:54.470196  5933 caffe.cpp:239] Starting Optimization
F0318 20:19:54.470221  5933 caffe.cpp:245] Multi-GPU execution not available - rebuild with USE_NCCL
*** Check failure stack trace: ***
    @     0x7f3cd843a5cd  google::LogMessage::Fail()
    @     0x7f3cd843c433  google::LogMessage::SendToLog()
    @     0x7f3cd843a15b  google::LogMessage::Flush()
    @     0x7f3cd843ce1e  google::LogMessageFatal::~LogMessageFatal()
    @           0x40be04  train()
    @           0x407588  main
    @     0x7f3cd6b95830  __libc_start_main
    @           0x407e59  _start
    @              (nil)  (unknown)
